{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective in this exercise is to build the functions that you will need to create your histogram filter. The histogram filter represents the state as a fixed set of hypotheses that correspond to the centroids of evenly spaced cells. Each one of these hypothesis has an associated weight, and the weights should sum to one. As a result, the histogram corresponds to a valid belief distribution over the state space. In math we can write this as a weighted sum of Dirac delta functions:\n",
    "\n",
    "$bel(x_t) =  \\sum_{i=1}^N w^i_t \\delta(x_t - x^i)$\n",
    "\n",
    "The API for this (and really any) filter will comprise three functions: `prior()`, `predict()` and `update()`. The `prior()` function sets up the initial belief weights, $w_0$ over the histogram. \n",
    "\n",
    "The `predict()` function propagates forward the belief weights based on the motion model and the control, $u_t$. This amounts to propagating the centroids of each of the cells forward and then adding all of the weight up that lands in each bin. \n",
    "\n",
    "$\\overline{bel}(x_t) =  \\sum_{i=1}^N \\sum_{j=1}^N w_{t-1}^j p(x^i|x^j,u_t) \\delta(x_t - x^i)$\n",
    "\n",
    "In our case we will be using the odometry as a proxy for the control input so that we may use a simple kinematic model of the robot. \n",
    "\n",
    "Finally, the `update()` function takes a measurement and uses it to update the weights of the histogram bins based on the incoming measurement, $z_t$. This is achieved by multiplying the weight in each bin by the likelihood that the measurement was generated by the state corresponding to the centroid of that bin:\n",
    "\n",
    "$bel(x_t) = \\sum_{i=1}^N \\frac{\\overline{w}^i_t p(z_t|x^i)}{\\displaystyle\\sum_{j=1}^N \\overline{w}^j_t p(z_t|x^j)}\\delta(x_t - x^i)$\n",
    "\n",
    "In this notebook we will proceed by loading one image and using the line detection and ground projection algorithms (we can consider them as a black box here) to detect all of the white and yellow line segments. Each line segment will contribute a vote in the measurement likelihood. \n",
    "\n",
    "After completing the notebook, apply the same concepts in the functions within [histogram_filter.py](../../packages/solution/histogram_filter.py) (fill in the TODOs).\n",
    "\n",
    "After running `dts code build` these functions can be used on the simulated or real Duckiebot using `dts code workbench --sim` or `dts code workbench -b <ROBOT_NAME>`. This will use the real (or simulated) data coming from your camera instead of the single image that we loaded here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by importing some things we will need\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "from math import floor, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's load the image that we will use. Feel free to change it, \n",
    "# but the calibrations in the setup/calibrations folder should correspond to the robot\n",
    "# that took the image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "img = cv2.imread(\"../../assets/images/pic1.png\")\n",
    "imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the state here to be the comprised of the distance from the center of the lane $d$ and the angle relative to the lane $\\phi$. \n",
    "\n",
    "![](../../assets/images/state.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will load parameters from the configuration file\n",
    "# These are the same parameters that will be loaded when we do \n",
    "# dts code workbench. Feel free to experiment with different values\n",
    "# for any of the parameters\n",
    "import yaml\n",
    "with open(\"../../packages/histogram_lane_filter/config/histogram_lane_filter_node/default.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "hp = params[\"lane_filter_histogram_configuration\"]\n",
    "print(hp)\n",
    "\n",
    "d, phi = np.mgrid[hp['d_min'] : hp['d_max'] : hp['delta_d'], hp['phi_min'] : hp['phi_max'] : hp['delta_phi']]\n",
    "\n",
    "# We are going to organize them into some data structures so that they are easier to move around\n",
    "grid_spec = {\n",
    "    \"d\": d,\n",
    "    \"phi\": phi,\n",
    "    \"delta_d\": hp['delta_d'],\n",
    "    \"delta_phi\": hp['delta_phi'],\n",
    "    \"d_min\": hp['d_min'],\n",
    "    \"d_max\": hp['d_max'],\n",
    "    \"phi_min\": hp['phi_min'],\n",
    "    \"phi_max\": hp['phi_max'],\n",
    "}\n",
    "road_spec = {\n",
    "    \"linewidth_white\": hp['linewidth_white'],\n",
    "    \"linewidth_yellow\": hp['linewidth_yellow'],\n",
    "    \"lanewidth\": hp['lanewidth'],\n",
    "}\n",
    "robot_spec = {\n",
    "    \"wheel_radius\": hp['wheel_radius'],\n",
    "    \"wheel_baseline\": hp['wheel_baseline'],\n",
    "    \"encoder_resolution\": hp['encoder_resolution'],\n",
    "}\n",
    "\n",
    "# The \"cov_mask\" is effectively the process model covariance\n",
    "cov_mask = [hp['sigma_d_mask'], hp['sigma_phi_mask']]\n",
    "belief = np.empty(d.shape)\n",
    "mean_0 = [hp['mean_d_0'], hp['mean_phi_0']]\n",
    "cov_0 = [[hp['sigma_d_0'], 0], [0, hp['sigma_phi_0']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define the prior function. In this case we choose\n",
    "# to initialize the historgram based on a Gaussian distribution around [0,0]\n",
    "def histogram_prior(belief, grid_spec, mean_0, cov_0):\n",
    "    pos = np.empty(belief.shape + (2,))\n",
    "    pos[:, :, 0] = grid_spec[\"d\"]\n",
    "    pos[:, :, 1] = grid_spec[\"phi\"]\n",
    "    RV = multivariate_normal(mean_0, cov_0)\n",
    "    belief = RV.pdf(pos)\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define the predict function\n",
    "\n",
    "\n",
    "def histogram_predict(belief, left_encoder_ticks, right_encoder_ticks, grid_spec, robot_spec, cov_mask):\n",
    "        belief_in = belief\n",
    "\n",
    "        \n",
    "        # TODO propagate each centroid forward using the kinematic function\n",
    "        alpha = 2 * np.pi / robot_spec['encoder_resolution']\n",
    "        \n",
    "        left_wheel_d = robot_spec['wheel_radius'] * left_encoder_ticks * alpha\n",
    "        right_wheel_d = robot_spec['wheel_radius'] * right_encoder_ticks * alpha\n",
    "\n",
    "        displacement = (left_wheel_d + right_wheel_d) / 2\n",
    "        phi = (right_wheel_d - left_wheel_d) / robot_spec['wheel_baseline']\n",
    "\n",
    "        d_t = grid_spec['d'] + displacement\n",
    "        phi_t = grid_spec['phi'] + phi\n",
    "\n",
    "        p_belief = np.zeros(belief.shape)\n",
    "\n",
    "        # Accumulate the mass for each cell as a result of the propagation step\n",
    "        for i in range(belief.shape[0]):\n",
    "            for j in range(belief.shape[1]):\n",
    "                # If belief[i,j] there was no mass to move in the first place\n",
    "                if belief[i, j] > 0:\n",
    "                    # Now check that the centroid of the cell wasn't propagated out of the allowable range\n",
    "                    if (\n",
    "                        d_t[i, j] > grid_spec['d_max']\n",
    "                        or d_t[i, j] < grid_spec['d_min']\n",
    "                        or phi_t[i, j] < grid_spec['phi_min']\n",
    "                        or phi_t[i, j] > grid_spec['phi_max']\n",
    "                    ):\n",
    "                        continue\n",
    "                    \n",
    "                    # TODO Now find the cell where the new mass should be added\n",
    "                    i_new = int((d_t[i, j] - grid_spec['d_min']) // grid_spec['delta_d'])\n",
    "                    j_new = int((phi_t[i, j] - grid_spec['phi_min']) // grid_spec['delta_phi'])\n",
    "\n",
    "                    p_belief[i_new, j_new] += belief[i, j]\n",
    "\n",
    "        # Finally we are going to add some \"noise\" according to the process model noise\n",
    "        # This is implemented as a Gaussian blur over the histogram\n",
    "        s_belief = np.zeros(belief.shape)\n",
    "        gaussian_filter(p_belief, cov_mask, output=s_belief, mode=\"constant\")\n",
    "\n",
    "        if np.sum(s_belief) == 0:\n",
    "            return belief_in\n",
    "        belief = s_belief / np.sum(s_belief)\n",
    "        return belief\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to work on building the measurement likelihood. We will have as an input a list of segments. Each segment has endpoints, a normal vector, and an associated color. For each segment, we will use basic geometry to figure out what position ($d$) and orientation ($\\phi$) the robot would have had to have been at to detect the specific segment assuming that it did in fact come from a road marking. \n",
    "\n",
    "There is a bit of annoying detail here since we can detect lines on either side of the actual lane markings. We use the normals to determine which side of the lane marking the line was on. The following shows the `lanewidth` and the `linewidth_yellow` and `linewidth_white` parameters.\n",
    "\n",
    "The following image shows a representations of how the detected line segments sit on an actual lane\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "  <img src=\"../../assets/images/03-histogram-filter/detected_line_segments.png\" alt=\"detected line segments\" width=\"200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start by doing a little bit of processing on the segments to remove anything that is behind the robot (why would it be behind?)\n",
    "# or a color not equal to yellow or white\n",
    "\n",
    "def prepare_segments(segments):\n",
    "    filtered_segments = []\n",
    "    for segment in segments:\n",
    "\n",
    "        # we don't care about RED ones for now\n",
    "        if segment.color != SegmentColor.WHITE and segment.color != SegmentColor.YELLOW:\n",
    "            continue\n",
    "        # filter out any segments that are behind us\n",
    "        if segment.points[0].x < 0 or segment.points[1].x < 0:\n",
    "            continue\n",
    "\n",
    "        filtered_segments.append(segment)\n",
    "    return filtered_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each segment we will generate a vote according to:\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "  <img src=\"../../assets/images/03-histogram-filter/Votingalgorithm.png\" alt=\"detected line segments\" width=\"1000\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_vote(segment, road_spec):\n",
    "    p1 = segment.points[0].as_array()\n",
    "    p2 = segment.points[1].as_array()\n",
    "    t_hat = (p2 - p1) / np.linalg.norm(p2 - p1)\n",
    "\n",
    "    n_hat = np.array([-t_hat[1], t_hat[0]])\n",
    "    d1 = np.inner(n_hat, p1)\n",
    "    d2 = np.inner(n_hat, p2)\n",
    "    l1 = np.inner(t_hat, p1)\n",
    "    l2 = np.inner(t_hat, p2)\n",
    "    if l1 < 0:\n",
    "        l1 = -l1\n",
    "    if l2 < 0:\n",
    "        l2 = -l2\n",
    "\n",
    "    l_i = (l1 + l2) / 2\n",
    "    d_i = (d1 + d2) / 2\n",
    "    phi_i = np.arcsin(t_hat[1])\n",
    "    if segment.color == SegmentColor.WHITE:  # right lane is white\n",
    "        if p1[0] > p2[0]:  # right edge of white lane\n",
    "            d_i -= road_spec['linewidth_white']\n",
    "        else:  # left edge of white lane\n",
    "\n",
    "            d_i = -d_i\n",
    "\n",
    "            phi_i = -phi_i\n",
    "        d_i -= road_spec['lanewidth'] / 2\n",
    "\n",
    "    elif segment.color == SegmentColor.YELLOW:  # left lane is yellow\n",
    "        if p2[0] > p1[0]:  # left edge of yellow lane\n",
    "            d_i -= road_spec['linewidth_yellow']\n",
    "            phi_i = -phi_i\n",
    "        else:  # right edge of white lane\n",
    "            d_i = -d_i\n",
    "        d_i = road_spec['lanewidth'] / 2 - d_i\n",
    "\n",
    "    return d_i, phi_i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the entire measurement likelihood by generating a vote for each line segment in the list that we received. The measurement likelihood will itself be a histogram:\n",
    "\n",
    "<p style=\"text-align: center\">\n",
    "  <img src=\"../../assets/images/03-histogram-filter/Histogram.png\" alt=\"detected line segments\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_measurement_likelihood(segments, road_spec, grid_spec):\n",
    "\n",
    "    # initialize measurement likelihood to all zeros\n",
    "    measurement_likelihood = np.zeros(grid_spec['d'].shape)\n",
    "\n",
    "    for segment in segments:\n",
    "        d_i, phi_i = generate_vote(segment, road_spec)\n",
    "\n",
    "        # if the vote lands outside of the histogram discard it\n",
    "        if d_i > grid_spec['d_max'] or d_i < grid_spec['d_min'] or phi_i < grid_spec['phi_min'] or phi_i > grid_spec['phi_max']:\n",
    "            continue\n",
    "\n",
    "        # TODO find the cell index that corresponds to the measurement d_i, phi_i\n",
    "        i = int((d_i - grid_spec['d_min']) // grid_spec['delta_d'])\n",
    "        j = int((phi_i - grid_spec['phi_min']) // grid_spec['delta_phi'])\n",
    "        \n",
    "        # Add one vote to that cell\n",
    "        measurement_likelihood[i, j] += 1\n",
    "\n",
    "    if np.linalg.norm(measurement_likelihood) == 0:\n",
    "        return None\n",
    "    measurement_likelihood /= np.sum(measurement_likelihood)\n",
    "    return measurement_likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need for the update function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_update(belief, segments, road_spec, grid_spec):\n",
    "    # prepare the segments for each belief array\n",
    "    segmentsArray = prepare_segments(segments)\n",
    "    # generate all belief arrays\n",
    "\n",
    "    measurement_likelihood = generate_measurement_likelihood(segmentsArray, road_spec, grid_spec)\n",
    "\n",
    "    if measurement_likelihood is not None:\n",
    "        # TODO: combine the prior belief and the measurement likelihood to get the posterior belief\n",
    "        # Don't forget that you may need to normalize to ensure that the output is valid probability distribution\n",
    "        posterior_belief = belief * measurement_likelihood\n",
    "        posterior_belief /= np.sum(posterior_belief)\n",
    "    return (measurement_likelihood, posterior_belief)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined the `prior()`, `predict()` and `update()` functions. We will test one cycle of the filter here to see if things look reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start initializing the belief:\n",
    "belief = histogram_prior(belief, grid_spec, mean_0, cov_0)\n",
    "imshow(belief)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's generate some fake encoder data and do one step of the prediction function:\n",
    "\n",
    "left = 10 # left ticks\n",
    "right = 20 # right ticks\n",
    "belief = histogram_predict(belief, left, right, grid_spec, robot_spec, cov_mask)\n",
    "imshow(belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Union, List\n",
    "from dt_computer_vision.camera import CameraModel, NormalizedImagePoint, Pixel\n",
    "from dt_computer_vision.ground_projection import GroundProjector\n",
    "from dt_computer_vision.ground_projection.rendering import draw_grid_image, debug_image\n",
    "from dt_computer_vision.ground_projection.types import GroundPoint\n",
    "from dt_computer_vision.line_detection import LineDetector, ColorRange, Detections\n",
    "from dt_computer_vision.line_detection.rendering import draw_segments\n",
    "from dt_state_estimation.lane_filter.types import Segment, SegmentColor, SegmentPoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code will take the image that we loaded, detect the line segments, and project them onto the ground plane. \n",
    "# We don't need to worry too much about details here.\n",
    "Color = Tuple[int, int, int]\n",
    "\n",
    "camera_info: Dict[str, Union[np.ndarray, int]] = \\\n",
    "    {\n",
    "        \"width\": 640,\n",
    "        \"height\": 480,\n",
    "        \"K\": np.reshape(\n",
    "            [\n",
    "                295.79606866959824,\n",
    "                0.0,\n",
    "                321.2621599038631,\n",
    "                0.0,\n",
    "                299.5389048862878,\n",
    "                241.73616515312332,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                1.0,\n",
    "            ],\n",
    "            (3, 3)\n",
    "        ),\n",
    "        \"D\": [\n",
    "            -0.23543978771661125,\n",
    "            0.03637781479419574,\n",
    "            -0.0033069818601306755,\n",
    "            -0.0012140708179525926,\n",
    "            0.0,\n",
    "        ],\n",
    "        \"P\": np.reshape(\n",
    "            [\n",
    "                201.14027404785156,\n",
    "                0.0,\n",
    "                319.5586620845679,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                239.74398803710938,\n",
    "                237.60151004037834,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                1.0,\n",
    "                0.0,\n",
    "            ],\n",
    "            (3, 4)\n",
    "        ),\n",
    "        \"H\": np.reshape(\n",
    "            [\n",
    "                8.56148231e-03,\n",
    "                2.22480148e-01,\n",
    "                4.24318934e-01,\n",
    "                -5.67022044e-01,\n",
    "                -1.13258040e-03,\n",
    "                6.81113839e-04,\n",
    "                5.80917161e-02,\n",
    "                4.35079347e+00,\n",
    "                1.0],\n",
    "            (3, 3)\n",
    "        ),\n",
    "    }\n",
    "crop_top = 200\n",
    "image_crop = [0, crop_top, 640, camera_info[\"height\"] - crop_top]\n",
    "x, y, w, h = image_crop\n",
    "img_cropped = img[y:y + h, x:x + w, :]\n",
    "_K = camera_info[\"K\"]\n",
    "_K[0][2] = _K[0][2] - x\n",
    "_K[1][2] = _K[1][2] - y\n",
    "# - update P\n",
    "_P = camera_info[\"P\"]\n",
    "_P[0][2] = _P[0][2] - x\n",
    "_P[1][2] = _P[1][2] - y\n",
    "\n",
    "\n",
    "# colors\n",
    "color_ranges: Dict[str, ColorRange] = {\n",
    "    \"white\": ColorRange.fromDict({\n",
    "        \"low\": [0, 0, 150],\n",
    "        \"high\": [180, 100, 255]\n",
    "    }),\n",
    "    \"yellow\": ColorRange.fromDict({\n",
    "        \"low\": [0, 100, 100],\n",
    "        \"high\": [45, 255, 255]\n",
    "    })\n",
    "}\n",
    "colors: Dict[str, Color] = {\n",
    "    \"red\": (0, 0, 255),\n",
    "    \"yellow\": (0, 255, 255),\n",
    "    \"white\": (255, 255, 255),\n",
    "}\n",
    "color_order = [\"yellow\", \"white\"]\n",
    "colors_to_detect = [color_ranges[c] for c in color_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_lines(img_cropped):\n",
    "    \n",
    "    detector = LineDetector()\n",
    "    color_detections: List[Detections] = detector.detect(img_cropped, colors_to_detect)\n",
    "    lines: Dict[str, dict] = {}\n",
    "    for i, detections in enumerate(color_detections):\n",
    "        color = color_order[i]\n",
    "        # pack detections in a dictionary\n",
    "        lines[color] = {\n",
    "            \"lines\": detections.lines.tolist(),\n",
    "            \"centers\": detections.centers.tolist(),\n",
    "            \"normals\": detections.normals.tolist(),\n",
    "            \"color\": color_ranges[color].representative\n",
    "        }\n",
    "    image_w_dets = draw_segments(img_cropped, {color_ranges[\"yellow\"]: color_detections[0]})\n",
    "    image_w_dets = draw_segments(image_w_dets, {color_ranges[\"white\"]: color_detections[1]})\n",
    "    plt.figure(0)\n",
    "    imshow(cv2.cvtColor(image_w_dets,cv2.COLOR_BGR2RGB))\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_projected_segments(lines):\n",
    "    camera = CameraModel(\n",
    "        width=camera_info[\"width\"],\n",
    "        height=camera_info[\"height\"],\n",
    "        K=camera_info[\"K\"],\n",
    "        D=camera_info[\"D\"],\n",
    "        P=camera_info[\"P\"],\n",
    "        H=camera_info[\"H\"],\n",
    "    )\n",
    "    projector = GroundProjector(camera)\n",
    "    segments: List[Segment] = []\n",
    "    colored_segments: Dict[Color, List[Tuple[GroundPoint, GroundPoint]]] = {}\n",
    "    grid = draw_grid_image((400, 400))\n",
    "\n",
    "    for color, colored_lines in lines.items():\n",
    "        grounded_segments: List[Tuple[GroundPoint, GroundPoint]] = []\n",
    "        for line in colored_lines[\"lines\"]:\n",
    "            # distorted pixels\n",
    "            p0: Pixel = Pixel(line[0], line[1])\n",
    "            p1: Pixel = Pixel(line[2], line[3])\n",
    "            # distorted pixels to rectified pixels\n",
    "            p0_rect: Pixel = camera.rectifier.rectify_pixel(p0)\n",
    "            p1_rect: Pixel = camera.rectifier.rectify_pixel(p1)\n",
    "            # rectified pixel to normalized coordinates\n",
    "            p0_norm: NormalizedImagePoint = camera.pixel2vector(p0_rect)\n",
    "            p1_norm: NormalizedImagePoint = camera.pixel2vector(p1_rect)\n",
    "            # project image point onto the ground plane\n",
    "            grounded_p0: SegmentPoint = projector.vector2ground(p0_norm)\n",
    "            grounded_p1: SegmentPoint = projector.vector2ground(p1_norm)\n",
    "            # add grounded segment to output\n",
    "            segments.append(Segment(\n",
    "                points=[grounded_p0, grounded_p1],\n",
    "                color=SegmentColor(color)\n",
    "            ))\n",
    "            grounded_segments.append((grounded_p0, grounded_p1))\n",
    "\n",
    "        colored_segments[colors[color]] = grounded_segments\n",
    "    image_w_segs = debug_image(colored_segments, (400, 400), background_image=grid)\n",
    "    image_w_segs_rgb = image_w_segs[:, :, [2, 1, 0]]\n",
    "    plt.figure(1)\n",
    "    imshow(image_w_segs_rgb)\n",
    "    return segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "lines = detect_lines(img_cropped)\n",
    "segments = lines_to_projected_segments(lines)\n",
    "# Finally we can take the ground projected segments and call our update function\n",
    "(measurement_likelihood, belief) = histogram_update(belief, segments, road_spec, grid_spec)\n",
    "plt.figure(2)\n",
    "imshow(belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the notebook, apply the same concepts in the functions within [histogram_filter.py](../../packages/solution/histogram_filter.py) (fill in the TODOs) and then test it with the process described in the [README](../../README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
